{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ix73zuXvXiq4"
      },
      "outputs": [],
      "source": [
        "!pip install onnx\n",
        "#imports\n",
        "import math\n",
        "#PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "#Import SciPy to load the Flowers-102 dataset from the .mat format\n",
        "import scipy.io\n",
        "\n",
        "#Other imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Import time so that we can train the model within the 12 hour time limit\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6cZhX6bkZOtH"
      },
      "outputs": [],
      "source": [
        "#Define transforms\n",
        "trainingTransform = transforms.Compose([\n",
        "    transforms.Resize(224), #Change this value to edit the image size\n",
        "    transforms.RandomRotation(90), #Rotates each image by a random angle between 0-90 degrees\n",
        "    transforms.CenterCrop(224), #Must be the same as resize value. This is used to ensure the image is square\n",
        "    #Default probability for both flips is p=0.5, can be changed if needed\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0,1) #zerocenter normalization\n",
        "])\n",
        "\n",
        "trainingTransformBrightness = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomRotation(90),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ColorJitter(contrast=(0.5, 0.9), brightness=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0,1)\n",
        "])\n",
        "\n",
        "trainingTransformSaturation = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomRotation(90),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ColorJitter(saturation=(0.5, 0.9), hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0,1)\n",
        "])\n",
        "\n",
        "nonTrainTransform = transforms.Compose([\n",
        "    #Same as training transform without flipping as required\n",
        "    #by assessment rules\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0,1)\n",
        "])\n",
        "\n",
        "#Load Flowers-102 dataset and split it into train, validate and test splits\n",
        "trainingSet = datasets.Flowers102(root=\"./flowers\", split=\"train\", download=True, transform=trainingTransform)\n",
        "trainingSet2 = datasets.Flowers102(root=\"./flowers\", split=\"train\", download=True)\n",
        "trainingSetBright, trainingSetSat = random_split(trainingSet2, (510, 510)) #splits the data set into non-overlapping halfs\n",
        "trainingSetSat.dataset.transform = trainingTransformSaturation\n",
        "trainingSetBright.dataset.transform = trainingTransformBrightness\n",
        "trainingSet = ConcatDataset([trainingSet, trainingSetBright, trainingSetBright])\n",
        "\n",
        "validationSet = datasets.Flowers102(root=\"./flowers\", split=\"val\", download=True, transform=nonTrainTransform)\n",
        "testingSet = datasets.Flowers102(root=\"./flowers\", split=\"test\", download=True, transform=nonTrainTransform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nqLMBjWgSxX"
      },
      "outputs": [],
      "source": [
        "#Checking the splits are the correct length\n",
        "print(len(trainingSet))\n",
        "print(len(validationSet))\n",
        "print(len(testingSet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvxX8vX_hPHg"
      },
      "outputs": [],
      "source": [
        "#Checking the training transformations are ok\n",
        "figure = plt.figure(figsize=(10,10))\n",
        "col, row = 2, 2\n",
        "for i in range(1, 5): #TODO: Change this to be rows * columns\n",
        "  randImg = torch.randint(len(trainingSet), size=(1,)).item() #Size defines the shape of the tensor\n",
        "  img, label = trainingSet[randImg]\n",
        "  figure.add_subplot(row, col, i)\n",
        "  plt.title(label)\n",
        "  plt.axis(False)\n",
        "  plt.imshow(img.squeeze().permute(1,2,0)) #Permute gets the dimentions in the correct order\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bjq9-0zdmPSt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "#Checking if collab can connect to a GPU\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "alXg-dq0nhJW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (netLayers): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU()\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): ReLU()\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): ReLU()\n",
            "    (20): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU()\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU()\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (31): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (33): Flatten(start_dim=1, end_dim=-1)\n",
            "    (34): LazyLinear(in_features=0, out_features=4096, bias=True)\n",
            "    (35): ReLU()\n",
            "    (36): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (37): Dropout(p=0.8, inplace=False)\n",
            "    (38): LazyLinear(in_features=0, out_features=4096, bias=True)\n",
            "    (39): ReLU()\n",
            "    (40): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (41): Dropout(p=0.8, inplace=False)\n",
            "    (42): LazyLinear(in_features=0, out_features=1000, bias=True)\n",
            "    (43): ReLU()\n",
            "    (44): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (45): Dropout(p=0.5, inplace=False)\n",
            "    (46): Linear(in_features=1000, out_features=102, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Inari\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ],
      "source": [
        "#The CNN itself\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #DEFINING THE LAYERS. THIS IS WHERE WE WILL SPEND MOST OF OUR TIME\n",
        "    self.netLayers = nn.Sequential(\n",
        "        # block 1 \n",
        "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64),\n",
        "\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.BatchNorm2d(64),\n",
        " \n",
        "        #block 2\n",
        "        \n",
        "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=(1,1), padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(128),\n",
        "\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.BatchNorm2d(128),\n",
        "\n",
        "        #block3\n",
        "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=(1,1), padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(256),\n",
        "\n",
        "        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=(1,1), padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(256),\n",
        "\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.BatchNorm2d(256),\n",
        "        \n",
        "        \n",
        "        #block 4\n",
        "        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=(1,1), padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(512),\n",
        "        \n",
        "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=(1,1), padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(512),\n",
        "\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.BatchNorm2d(512),\n",
        "\n",
        "        #block 5\n",
        "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=(1,1), padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(512),\n",
        "\n",
        "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=(1,1), padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.BatchNorm2d(512),\n",
        "\n",
        "        nn.Flatten(),\n",
        "\n",
        "        # fully connected layer\n",
        "        nn.LazyLinear(4096),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(4096),\n",
        "        nn.Dropout(0.8),\n",
        "\n",
        "        nn.LazyLinear(4096),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(4096),\n",
        "        nn.Dropout(0.8),\n",
        "\n",
        "        nn.LazyLinear(1000),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(1000),\n",
        "        nn.Dropout(0.5),\n",
        "\n",
        "        nn.Linear(1000, 102), #102 for the classifiers\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "      result = self.netLayers(x)\n",
        "      #print(result.shape)\n",
        "      return result\n",
        "  \n",
        "\n",
        "print(CNN())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5hamjNab3zZC"
      },
      "outputs": [],
      "source": [
        "#Code to train the CNN based on a set number of epochs\n",
        "def epochCountTrain(trainLoader, cnn, optimizer, lossFunction):\n",
        "  totalLoss, correct = 0, 0\n",
        "  size = len(trainLoader.dataset)\n",
        "  for i, data in enumerate(trainLoader, 0):\n",
        "    input, labels = data\n",
        "    input = input.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = cnn(input)\n",
        "    loss = lossFunction(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    totalLoss += loss.item()\n",
        "    correct += (output.argmax(1)==labels).sum().item()\n",
        "    if i % 20 == 0:\n",
        "      loss, currentLoss = loss.item(), (i + 1) * len(input)\n",
        "      print(f\"loss: {loss:>7f}    [{currentLoss:>5d}/{size:>5d}]\")\n",
        "      \n",
        "  epochTrainLoss.append(float(loss))\n",
        "  epochTrainAccuracy.append(round((correct/size)*100, 1))\n",
        "  print(f\"\\nAvg train loss: {(totalLoss/len(trainLoader)):>8f}\")\n",
        "  print(f\"Train accuracy = {((correct/size) * 100): >0.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Wb9Znmi1O5Tq"
      },
      "outputs": [],
      "source": [
        "#Code to guess accuracy based on validation set\n",
        "def validation(valLoader, cnn, lossFunction):\n",
        "  valSize = len(valLoader.dataset)\n",
        "  correct = 0\n",
        "  loss = []\n",
        "  with torch.no_grad(): #as we are not calling backward, use no grad to save memory\n",
        "    for batch in valLoader:\n",
        "      input, labels = batch\n",
        "      input = input.to(device)\n",
        "      labels = labels.to(device)\n",
        "      prediciton = cnn(input)\n",
        "      loss.append(lossFunction(prediciton, labels).item())\n",
        "      correct += (labels == prediciton.argmax(1)).sum().item()\n",
        "  \n",
        "  epochValLoss.append((np.average(loss)))\n",
        "  epochValAccuracy.append(round((correct/valSize)*100, 1))\n",
        "  print(f\"Accuracy on validation set = {((correct / valSize) * 100):>0.1f}%\")\n",
        "  print(f\"Average loss on validation set = {(np.average(loss))}\\n\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fagMwzmlfasX"
      },
      "outputs": [],
      "source": [
        "#Code that gets the accuracy of the test set!\n",
        "def test(testLoader, cnn):\n",
        "  testSize = len(testLoader.dataset)\n",
        "  correct = 0\n",
        "  top5 = 0 \n",
        "  with torch.no_grad():\n",
        "    for batch in testLoader:\n",
        "      input, labels = batch\n",
        "      input = input.to(device)\n",
        "      labels = labels.to(device)\n",
        "      prediciton = cnn(input)\n",
        "      correct +=(prediciton.argmax(dim=1) == labels).sum().item()\n",
        "      #top5 += sum((labels in prediciton.topk(5, dim=1)))\n",
        "  print(\"----------------------------------------------------\")    \n",
        "  print(f\"Accuracy on test set = {((correct / testSize) * 100):>0.1f}%\")\n",
        "  #print(f\"top5: {((top5 / testSize) * 100):>0.1f}%\")\n",
        "  print(\"----------------------------------------------------\")  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Creating a new CNN\n",
        "model = CNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Loading a CNN\n",
        "PATH = \"./mp510.pth\" #Change to wherever the .pth file is located\n",
        "model = CNN()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RRqyaVjRxtdI"
      },
      "outputs": [],
      "source": [
        "#Lists for graphs\n",
        "epochTrainLoss = []\n",
        "epochTrainAccuracy = []\n",
        "\n",
        "epochValLoss = []\n",
        "epochValAccuracy = []\n",
        "\n",
        "epochCountList = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JcwbAQ2QChCz"
      },
      "outputs": [],
      "source": [
        "#Instantiate the model, loss function and optimiser, done to prevent resets when rerunning the code below\n",
        "epochCount = 1\n",
        "learningRate = 0.00005\n",
        "batchSize = 32\n",
        "lossFunction = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = AdamW(lr=learningRate, params=model.parameters(), weight_decay=0.1)\n",
        "trainDataloader = DataLoader(trainingSet, batch_size=batchSize, shuffle=True)\n",
        "valDataloader = DataLoader(validationSet, batch_size=batchSize, shuffle=True)\n",
        "testDataloader = DataLoader(testingSet, batch_size=batchSize, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sFwej_AA73pS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2\n",
            "loss: 0.399134    [   32/ 2040]\n",
            "loss: 0.518277    [  672/ 2040]\n",
            "loss: 0.264113    [ 1312/ 2040]\n",
            "loss: 0.478978    [ 1952/ 2040]\n",
            "\n",
            "Avg train loss: 0.371001\n",
            "Train accuracy = 91.3%\n",
            "Accuracy on validation set = 54.3%\n",
            "Average loss on validation set = 2.0986083298921585\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Actual code to get it all running\n",
        "for i in range(epochCount):\n",
        "  print(f\"Epoch {len(epochCountList)+1}\")\n",
        "  model.train()\n",
        "  epochCountTrain(trainDataloader, model, optimizer, lossFunction)\n",
        "  model.eval()\n",
        "  validation(valDataloader, model, lossFunction)\n",
        "  epochCountList.append(len(epochCountList) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlb29lwuDHN9"
      },
      "outputs": [],
      "source": [
        "#plot the loss and accuracy of the training and validation set\n",
        "plt.plot(epochCountList, epochTrainLoss, label=\"Training loss\")\n",
        "plt.plot(epochCountList, epochValLoss, label=\"Validation loss\")\n",
        "plt.title(\"Train & validation loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochCountList, epochTrainAccuracy, label=\"Training accuracy\")\n",
        "plt.plot(epochCountList, epochValAccuracy, label=\"Validation accuracy\")\n",
        "plt.title(\"Train & validation accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zzJrVTcDpbl"
      },
      "outputs": [],
      "source": [
        "#Save the model to the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fryvcrUTf9nZ"
      },
      "outputs": [],
      "source": [
        "PATH =\"./mp510.pth\" #EDIT TO DEFINE WHERE TO SAVE\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Lz8OYXyfDLw7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------\n",
            "Accuracy on test set = 43.6%\n",
            "----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#Run the model on the test set\n",
        "test(testDataloader, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDcci50Ehyql"
      },
      "outputs": [],
      "source": [
        "for test_images, _ in trainDataloader:  \n",
        "  torch.onnx.export(model, test_images.to(device), \"alexnet.onnx\", verbose=True)\n",
        "  break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
