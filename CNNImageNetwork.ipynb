{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM564c9EUnMkEeNWR8gRfUj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shella688/INT2-GROUP12/blob/main/CNNImageNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aZM2vsQk1tcB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    # Creating layers ooooo spooky\n",
        "    super(SimpleNet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "    # Input layers has input images have 3 channels - RGB\n",
        "    # We want to apply 12 feature detectors, hence 12 output channels\n",
        "    # Stride = convolution moves 1 pixel at a time\n",
        "    # Padding 1 = images padded w/ zeros so input size==output\n",
        "    # Out channels of this layer == In channels of next layer\n",
        "\n",
        "    self.relu1 = nn.ReLU()\n",
        "    # ReLU activation function\n",
        "    # Appled to incoming features\n",
        "    # anything <0 is set to 0, otherwise kept the same\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "    self.relu2 = nn.ReLU()\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "    # Reduces dimension of image\n",
        "    # 4 pixels become 1\n",
        "    \n",
        "    self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
        "    self.relu3 = nn.ReLU()\n",
        "\n",
        "    self.conv4 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
        "    self.relu4 = nn.ReLU()\n",
        "\n",
        "    self.fc = nn.Linear(in_features=16 * 16 * 24, out_features=num_classes)\n",
        "    # Final layer\n",
        "    # standard, fully-connect layer\n",
        "\n",
        "  def forward(self, input):\n",
        "    output = self.conv1(input)\n",
        "    output = self.relu1(output)\n",
        "\n",
        "    output = self.conv2(output)\n",
        "    output = self.relu2(output)\n",
        "\n",
        "    output = self.pool(output)\n",
        "\n",
        "    output = self.conv3(output)\n",
        "    output = self.relu3(output)\n",
        "\n",
        "    output = self.conv4(output)\n",
        "    output = self.relu4(output)\n",
        "\n",
        "    output = self.view(-1, 16*16*24)\n",
        "    # Flatten entire feature map before passing to image\n",
        "\n",
        "    output = self.fc(output)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is, however, a long-winded way of doing things. We can ~ modularise it ~"
      ],
      "metadata": {
        "id": "XdeqC08udlbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Below code does similar to above, but in modular fashion\n",
        "# it would form part of a larger SimpleNet\n",
        "\n",
        "class Unit(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(Unit, self).__init__()\n",
        "\n",
        "    self.conv = nn.Conv2d(in_channels=in_channels, kernel_size=3, \n",
        "                          out_channels=out_channels, stride=1, padding=1)\n",
        "    self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, input):\n",
        "    output = self.conv(input)\n",
        "    output = self.bn(output) \n",
        "    output = self.relu(output) \n",
        "\n",
        "    return output\n",
        "\n",
        "class SimpleModularNet(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(SimpleModularNet, self).__init__()\n",
        "\n",
        "    # creates 14 layers, with max pooling in between \n",
        "    self.unit1 = Unit(in_channels=3, out_channels=32)\n",
        "    self.unit2 = Unit(in_channels=32, out_channels=32)\n",
        "    self.unit3 = Unit(32, 32)\n",
        "\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.unit4 = Unit(32, 64)\n",
        "    self.unit5 = Unit(64, 64)\n",
        "    self.unit6 = Unit(64, 64)\n",
        "    self.unit7 = Unit(64, 64)\n",
        "\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.unit8 = Unit(64, 128)\n",
        "    self.unit9 = Unit(128, 128)\n",
        "    self.unit10 = Unit(128, 128)\n",
        "    self.unit11 = Unit(128, 128)\n",
        "\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.unit12 = Unit(128, 128)\n",
        "    self.unit13 = Unit(128, 128)\n",
        "    self.unit14 = Unit(128, 128)\n",
        "\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
        "    # this turns feature map into 1x1x128\n",
        "    # giving us 128 input features\n",
        "\n",
        "    # Add units to sequential layer in numerical order\n",
        "    self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.unit4, \n",
        "                             self.unit5, self.unit6, self.unit7, self.unit8, \n",
        "                             self.unit9, self.unit10, self.unit11, self.unit12, \n",
        "                             self.unit13, self.unit14, self.avgpool)\n",
        "    \n",
        "    self.fc = nn.Linear(in_features=128, out_features=num_classes)\n",
        "\n",
        "  def forward(self, input):\n",
        "    output = self.net(input)\n",
        "    output = output.view(-1, 128)\n",
        "    # flattening output to also have 128 features\n",
        "    output = self.fc(output)\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "-5rsYDCQ6XTF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here, we're loading + augumenting data (specifically the CIFAR10 dataset, which contains 60,000 32x32 colour images in 10 different classes - aeroplanes, cars, birds, cats, deer, dogs, frogs, horsese, ships, trucks)"
      ],
      "metadata": {
        "id": "hcxRShDEh4mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "nFiLFhVodkLx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we define transformations for training set, randomly flip images,\n",
        "# crop them, and apply mean + std normalisation\n",
        "train_transformations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    # this transforms image into usable format\n",
        "\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "# Load training set\n",
        "train_set = CIFAR10(root=\"./data\", train=True, transform=train_transformations, \n",
        "                    download=True)\n",
        "\n",
        "# Create loader for said training set\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True,\n",
        "                          num_workers=1)\n",
        "# training data contains 32 images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3Pl5QbqihXC",
        "outputId": "168d1ddf-a2a8-4a64-d9fb-9ad385575aaa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We do a similar thing for test data\n",
        "test_transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "    # however, we don't need the various other transformations,\n",
        "    # because we're just testign if the model works, NOT training it\n",
        "    # to recognise images that may be flipped, rotated, and cropped\n",
        "])\n",
        "\n",
        "# load test set - set train to False \n",
        "test_set = CIFAR10(root=\"./data\", train=False, transform=test_transformations, \n",
        "                   download=True)\n",
        "\n",
        "# Loader for the test set, shuffle is this time set to False\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False,\n",
        "                         num_workers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGv7H7iqkqdg",
        "outputId": "dde0b7e8-a628-4965-8e64-2351a479f809"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to train the model. This uses a variation on gradient descent called the Adam optimiser"
      ],
      "metadata": {
        "id": "Sr0TlFMrm092"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "# check that GPU support is available\n",
        "cuda_avail = torch.cuda.is_available()\n",
        "\n",
        "# Create model, optimiser, and loss function\n",
        "# this is the point where you could import an existing model, ORRRR your\n",
        "# own homemade one!\n",
        "model = SimpleModularNet(num_classes=10)\n",
        "\n",
        "# if cude available, move model to GPU\n",
        "if cuda_avail:\n",
        "  model.cuda()\n",
        "\n",
        "# define optimiser and loss function \n",
        "optimiser = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "f7s18Vp2m69H"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now make a learning rate adjustment function\n",
        "# it divides learning rate by 10 every 30 epochs\n",
        "def learning_adjustment_rate(epoch):\n",
        "  lr = 0.001\n",
        "\n",
        "  if epoch > 180:\n",
        "    lr /= 1000000 \n",
        "  elif epoch > 150:\n",
        "    lr /= 100000\n",
        "  elif epoch > 120: \n",
        "    lr /= 10000 \n",
        "  elif epoch > 90:\n",
        "    lr /= 1000\n",
        "  elif epoch > 60:\n",
        "    lr /= 100 \n",
        "  elif epoch > 30:\n",
        "    lr /= 10\n",
        "\n",
        "  for param_group in optimiser.param_groups:\n",
        "    param_group[\"lr\"] = lr"
      ],
      "metadata": {
        "id": "wC4abBMqpodR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we give ourselves the ability to save + evaluate the model\n",
        "def save_model(epoch):\n",
        "  torch.save(model.state_dict(), \"cifar10model_{}.model\".format(epoch))\n",
        "  print(\"Checkpoint saved\")\n",
        "\n",
        "def test():\n",
        "  model.eval() \n",
        "  test_acc = 0.0 \n",
        "  for i, (images, labels) in enumerate(test_loader):\n",
        "    # iterate over test images\n",
        "\n",
        "    if cuda_avail:\n",
        "      images = Variable(images.cuda()) #(this is underlined but IS allowed)\n",
        "      labels = Variable(labels.cuda())\n",
        "\n",
        "    # Predict classes using images from test set \n",
        "    outputs = model(images)\n",
        "    _, prediction = torch.max(outputs.data, 1)\n",
        "    # maximum prediction picked and compared to actual class to obtain\n",
        "    # accuracy\n",
        "\n",
        "    test_acc += torch.sum(prediction == labels.data)\n",
        "\n",
        "  # calculat average accuracy and loss over all test images \n",
        "  test_acc /= 10000\n",
        "\n",
        "  return test_acc"
      ],
      "metadata": {
        "id": "JYlH0e_crKvm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train machine\n",
        "def train(num_epochs):\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0 \n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      # move images+labels to GPU if there is one \n",
        "      if cuda_avail:\n",
        "        images = Variable(images.cuda)\n",
        "        labels = Variable(labels.cuda)\n",
        "\n",
        "      # clear any accumulated gradients \n",
        "      optimiser.zero_grad()\n",
        "      # this is because weights in NN are adjusted based on the\n",
        "      # various calculated gradients for each batch \n",
        "      # Resetting to 0 prevents images from previous batch affecting\n",
        "      # current\n",
        "\n",
        "      # Predict classes using images from test set \n",
        "      outputs = model(images)\n",
        "      # compute loss based on pred vs actual\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      # backpropagate loss\n",
        "      loss.backward()\n",
        "\n",
        "      # now adjust parameters based on gradient \n",
        "      optimiser.step()\n",
        "\n",
        "      train_loss += loss.cpu().item() * images.size(0)\n",
        "      _, prediction = torch.max(outputs.data, 1)\n",
        "\n",
        "      train_acc += torch.sum(prediction == labels.data)\n",
        "\n",
        "    # adjust learning rate\n",
        "    learning_adjustment_rate(epoch)\n",
        "\n",
        "    # calculate average accuracy + loss over all trining images\n",
        "    train_acc /= 50000\n",
        "    train_loss /= 50000 \n",
        "\n",
        "    # evaluate on test set \n",
        "    test_acc = test()\n",
        "\n",
        "    # save model if test accuracy better than current best\n",
        "    if test_acc > best_acc:\n",
        "      save_model(epoch) \n",
        "      best_acc = test_acc\n",
        "\n",
        "    # Print the fun stuff\n",
        "    print(\"Epoch {}, Train accuracy: {}, Train loss: {}, \\\n",
        "    Test accuracy: {}\".format(epoch, train_acc, train_loss, test_acc))\n"
      ],
      "metadata": {
        "id": "isgXEZdVvUQF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ugCjlk9M3x4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  train(200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "GmelV0X_yH7o",
        "outputId": "e42fbba2-16af-4d24-e09a-450a65a38155"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-12ef2944829f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-f6da57e287b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m#Evaluate on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# Save the model if the test acc is greater than our current best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-f6da57e287b6>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sum(): argument 'input' (position 1) must be Tensor, not bool"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import needed packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Unit(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super(Unit,self).__init__()\n",
        "        \n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,kernel_size=3,out_channels=out_channels,stride=1,padding=1)\n",
        "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,input):\n",
        "        output = self.conv(input)\n",
        "        output = self.bn(output)\n",
        "        output = self.relu(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self,num_classes=10):\n",
        "        super(SimpleNet,self).__init__()\n",
        "\n",
        "        #Create 14 layers of the unit with max pooling in between\n",
        "        self.unit1 = Unit(in_channels=3,out_channels=32)\n",
        "        self.unit2 = Unit(in_channels=32, out_channels=32)\n",
        "        self.unit3 = Unit(in_channels=32, out_channels=32)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit4 = Unit(in_channels=32, out_channels=64)\n",
        "        self.unit5 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit6 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit7 = Unit(in_channels=64, out_channels=64)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit8 = Unit(in_channels=64, out_channels=128)\n",
        "        self.unit9 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit10 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit11 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit12 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit13 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit14 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
        "        \n",
        "        #Add all the units into the Sequential layer in exact order\n",
        "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, self.unit4, self.unit5, self.unit6\n",
        "                                 ,self.unit7, self.pool2, self.unit8, self.unit9, self.unit10, self.unit11, self.pool3,\n",
        "                                 self.unit12, self.unit13, self.unit14, self.avgpool)\n",
        "\n",
        "        self.fc = nn.Linear(in_features=128,out_features=num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.net(input)\n",
        "        output = output.view(-1,128)\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "\n",
        "#Define transformations for the training set, flip the images randomly, crop out and apply mean and std normalization\n",
        "train_transformations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32,padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#Load the training set\n",
        "train_set = CIFAR10(root=\"./data\",train=True,transform=train_transformations,download=True)\n",
        "\n",
        "#Create a loder for the training set\n",
        "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "\n",
        "\n",
        "#Define transformations for the test set\n",
        "test_transformations = transforms.Compose([\n",
        "   transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "\n",
        "])\n",
        "\n",
        "#Load the test set, note that train is set to False\n",
        "test_set = CIFAR10(root=\"./data\",train=False,transform=test_transformations,download=True)\n",
        "\n",
        "#Create a loder for the test set, note that both shuffle is set to false for the test loader\n",
        "test_loader = DataLoader(test_set,batch_size=batch_size,shuffle=False,num_workers=4)\n",
        "\n",
        "#Check if gpu support is available\n",
        "cuda_avail = torch.cuda.is_available()\n",
        "\n",
        "#Create model, optimizer and loss function\n",
        "model = SimpleNet(num_classes=10)\n",
        "\n",
        "if cuda_avail:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001,weight_decay=0.0001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#Create a learning rate adjustment function that divides the learning rate by 10 every 30 epochs\n",
        "def adjust_learning_rate(epoch):\n",
        "\n",
        "    lr = 0.001\n",
        "\n",
        "    if epoch > 180:\n",
        "        lr = lr / 1000000\n",
        "    elif epoch > 150:\n",
        "        lr = lr / 100000\n",
        "    elif epoch > 120:\n",
        "        lr = lr / 10000\n",
        "    elif epoch > 90:\n",
        "        lr = lr / 1000\n",
        "    elif epoch > 60:\n",
        "        lr = lr / 100\n",
        "    elif epoch > 30:\n",
        "        lr = lr / 10\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_models(epoch):\n",
        "    torch.save(model.state_dict(), \"cifar10model_{}.model\".format(epoch))\n",
        "    print(\"Checkpoint saved\")\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_acc = 0.0\n",
        "    for i, (images, labels) in enumerate(test_loader):\n",
        "      \n",
        "        if cuda_avail:\n",
        "                images = Variable(images.cuda())\n",
        "                labels = Variable(labels.cuda())\n",
        "\n",
        "        #Predict classes using images from the test set\n",
        "        outputs = model(images)\n",
        "        _,prediction = torch.max(outputs.data, 1)\n",
        "        # this was an ERROR 1: We do not need to convert tensor into numpy()\n",
        "        #prediction = prediction.cpu().numpy()\n",
        "        test_acc += torch.sum(prediction == labels.data)\n",
        "             \n",
        "\n",
        "\n",
        "    #Compute the average acc and loss over all 10000 test images\n",
        "    test_acc = test_acc / 10000\n",
        "\n",
        "    return test_acc\n",
        "\n",
        "def train(num_epochs):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_acc = 0.0\n",
        "        train_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            #Move images and labels to gpu if available\n",
        "            if cuda_avail:\n",
        "                images = Variable(images.cuda())\n",
        "                labels = Variable(labels.cuda())\n",
        "\n",
        "            #Clear all accumulated gradients\n",
        "            optimizer.zero_grad()\n",
        "            #Predict classes using images from the test set\n",
        "            outputs = model(images)\n",
        "            #Compute the loss based on the predictions and actual labels\n",
        "            loss = loss_fn(outputs,labels)\n",
        "            #Backpropagate the loss\n",
        "            loss.backward()\n",
        "\n",
        "            #Adjust parameters according to the computed gradients\n",
        "            optimizer.step()\n",
        "          \n",
        "            train_loss += loss.cpu().item() * images.size(0)\n",
        "            _, prediction = torch.max(outputs.data, 1)\n",
        "\n",
        "            # This was an ERROR 2\n",
        "            #train_loss += loss.cpu().data[0] * images.size(0)\n",
        "            #_, prediction = torch.max(outputs.data, 1)\n",
        "            \n",
        "            train_acc += torch.sum(prediction == labels.data)\n",
        "\n",
        "        #Call the learning rate adjustment function\n",
        "        adjust_learning_rate(epoch)\n",
        "\n",
        "        #Compute the average acc and loss over all 50000 training images\n",
        "        train_acc = train_acc / 50000\n",
        "        train_loss = train_loss / 50000\n",
        "\n",
        "        #Evaluate on the test set\n",
        "        test_acc = test()\n",
        "\n",
        "        # Save the model if the test acc is greater than our current best\n",
        "        if test_acc > best_acc:\n",
        "            save_models(epoch)\n",
        "            best_acc = test_acc\n",
        "\n",
        "\n",
        "        # Print the metrics\n",
        "        print(\"Epoch {}, Train Accuracy: {} , TrainLoss: {} , Test Accuracy: {}\".format(epoch, train_acc, train_loss,test_acc))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train(200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9CrYC2jysyU",
        "outputId": "9bb3b507-2f95-4032-c82a-39f9eeb08119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    }
  ]
}